{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723d4245-16a7-4936-8d7b-6c926a06eefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models, Tokenizer, and Label Encoder loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the saved models\n",
    "cnn_model = load_model(\"cnn_model.keras\")\n",
    "lstm_model = load_model(\"lstm_model.keras\")\n",
    "rnn_model = load_model(\"rnn_model.keras\")\n",
    "meta_model = load_model(\"meta_model.keras\")\n",
    "\n",
    "# Load the tokenizer\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Load the label encoder\n",
    "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "print(\"Models, Tokenizer, and Label Encoder loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82806416-5663-43bb-893d-50e9c2c59e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize NLTK tools\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Clean the text by converting to lowercase, removing non-alphabetic characters, etc.\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b71b9a7b-6545-4f20-8fa9-1f5102e4e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_category(headline):\n",
    "    # Step 1: Preprocess the input headline\n",
    "    headline = clean_text(headline)  # Clean the text\n",
    "    sequence = tokenizer.texts_to_sequences([headline])  # Tokenize the text\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=200)  # Pad the sequence to match the input shape\n",
    "\n",
    "    # Step 2: Get predictions from the base models (CNN, LSTM, GRU)\n",
    "    cnn_pred = cnn_model.predict(padded_sequence)\n",
    "    lstm_pred = lstm_model.predict(padded_sequence)\n",
    "    rnn_pred = rnn_model.predict(padded_sequence)\n",
    "\n",
    "    # Step 3: Stack predictions\n",
    "    stacked_pred = np.concatenate([cnn_pred, lstm_pred, rnn_pred], axis=1)\n",
    "\n",
    "    # Step 4: Get the final prediction from the meta-model\n",
    "    final_pred = meta_model.predict(stacked_pred)\n",
    "\n",
    "    # Step 5: Decode the predicted class using the label encoder\n",
    "    predicted_class = label_encoder.inverse_transform([np.argmax(final_pred)])\n",
    "\n",
    "    return predicted_class[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6652e82-44f5-4e13-b49e-69ff67f8ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "The predicted category for the headline is: POLITICS\n"
     ]
    }
   ],
   "source": [
    "# Example headline\n",
    "headline = \"Donald trump is making his comeback\"\n",
    "\n",
    "# Get the predicted category\n",
    "predicted_category = predict_category(headline)\n",
    "\n",
    "# Print the predicted category\n",
    "print(f\"The predicted category for the headline is: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd011c6e-ee42-4e8d-918c-37e1610e9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
